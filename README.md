# ä¸€ã€åŸºäºPaddleNLPçš„å¯¹è¯æ„å›¾è¯†åˆ«

## 1.æ¯”èµ›ä»‹ç»
æ„å›¾è¯†åˆ«æ˜¯æŒ‡åˆ†æç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚ï¼Œè¾“å‡ºä¸æŸ¥è¯¢è¾“å…¥æœ€ç›¸å…³çš„ä¿¡æ¯ï¼Œä¾‹å¦‚åœ¨æœç´¢ä¸­è¦æ‰¾ç”µå½±ã€æŸ¥å¿«é€’ã€å¸‚æ”¿åŠå…¬ç­‰éœ€æ±‚ï¼Œè¿™äº›éœ€æ±‚åœ¨åº•å±‚çš„æ£€ç´¢ç­–ç•¥ä¼šæœ‰å¾ˆå¤§çš„ä¸åŒï¼Œé”™è¯¯çš„è¯†åˆ«å‡ ä¹å¯ä»¥ç¡®å®šæ‰¾ä¸åˆ°èƒ½æ»¡è¶³ç”¨æˆ·éœ€æ±‚çš„å†…å®¹ï¼Œå¯¼è‡´äº§ç”Ÿéå¸¸å·®çš„ç”¨æˆ·ä½“éªŒï¼›åœ¨å¯¹è¯è¿‡ç¨‹ä¸­è¦å‡†ç¡®ç†è§£å¯¹æ–¹æ‰€æƒ³è¡¨è¾¾çš„æ„æ€ï¼Œè¿™æ˜¯å…·æœ‰å¾ˆå¤§æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚

æ„å›¾è¯†åˆ«çš„å‡†ç¡®æ€§èƒ½åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå½±å“ç€æœç´¢çš„å‡†ç¡®æ€§å’Œå¯¹è¯ç³»ç»Ÿçš„æ™ºèƒ½æ€§ï¼Œåœ¨æœ¬èµ›é¢˜ä¸­æˆ‘ä»¬éœ€è¦é€‰æ‰‹å¯¹ä¸­æ–‡å¯¹è¯è¿›è¡Œæ„å›¾è¯†åˆ«ã€‚

## 2.æ•°æ®é›†ä»‹ç»
- è®­ç»ƒæ•°æ®ï¼šå¤§çº¦1.2ä¸‡æ¡ä¸­æ–‡å¯¹è¯
- æµ‹è¯•æ•°æ®ï¼š3000æ¡æ— æ ‡æ³¨å¯¹è¯

## 3.æäº¤æ ·å¼
è¯„åˆ†ä½¿ç”¨å‡†ç¡®ç‡è¿›è¡Œè¯„åˆ†ï¼Œå‡†ç¡®ç‡å€¼è¶Šå¤§è¶Šå¥½ã€‚

- å®æ“æ–¹æ¡ˆä¸å…è®¸ä½¿ç”¨å¤–éƒ¨æ•°æ®é›†ï¼Œå…è®¸ä½¿ç”¨å…¬å¼€çš„å¤–éƒ¨é¢„è®­ç»ƒæ¨¡å‹ã€‚
- å®æ“æ–¹æ¡ˆéœ€è¦åœ¨æŒ‡å®šå¹³å°è¿›è¡Œè¯„åˆ†ï¼Œæäº¤csvæ ¼å¼ã€‚

æäº¤æ ·ä¾‹ï¼š
```
ID,Target
1,TVProgram-Play
2,HomeAppliance-Control
3,Audio-Play
4,Alarm-Update
5,HomeAppliance-Control
6,FilmTele-Play
7,FilmTele-Play
8,Music-Play
9,Calendar-Query
10,Video-Play
11,Alarm-Update
12,Music-Play
13,Travel-Query
14,TVProgram-Play
```

## 4.åŸºæœ¬æ€è·¯
![](https://ai-studio-static-online.cdn.bcebos.com/247187fe7fab49c2b602d464409e57b2ea2679a7c0584f34bdb4b53503d88797)



# äºŒã€ç¯å¢ƒå‡†å¤‡


```python
%cd ~
!git clone https://gitee.com/paddlepaddle/PaddleNLP/
```

    /home/aistudio
    æ­£å…‹éš†åˆ° 'PaddleNLP'...
    remote: Enumerating objects: 47494, done.[K
    remote: Counting objects: 100% (34730/34730), done.[K
    remote: Compressing objects: 100% (17072/17072), done.[K
    remote: Total 47494 (delta 23983), reused 27016 (delta 16711), pack-reused 12764[K
    æ¥æ”¶å¯¹è±¡ä¸­: 100% (47494/47494), 87.84 MiB | 4.86 MiB/s, å®Œæˆ.
    å¤„ç† delta ä¸­: 100% (32328/32328), å®Œæˆ.
    æ£€æŸ¥è¿æ¥... å®Œæˆã€‚



```python
!pip install -U paddlenlp
```

# ä¸‰ã€æ•°æ®å¤„ç†


```python
import pandas as pd
df=pd.read_csv('data/data208091/train.csv',sep='\t',header=None)
df.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>è¿˜æœ‰åŒé¸­å±±åˆ°æ·®é˜´çš„æ±½è½¦ç¥¨å—13å·çš„</td>
      <td>Travel-Query</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ä»è¿™é‡Œæ€ä¹ˆå›å®¶</td>
      <td>Travel-Query</td>
    </tr>
    <tr>
      <th>2</th>
      <td>éšä¾¿æ’­æ”¾ä¸€é¦–ä¸“è¾‘é˜æ¥¼é‡Œçš„ä½›é‡Œçš„æ­Œ</td>
      <td>Music-Play</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ç»™çœ‹ä¸€ä¸‹å¢“ç‹ä¹‹ç‹å˜›</td>
      <td>FilmTele-Play</td>
    </tr>
    <tr>
      <th>4</th>
      <td>æˆ‘æƒ³çœ‹æŒ‘æˆ˜ä¸¤æŠŠs686æ‰“çªå˜å›¢ç«çš„æ¸¸æˆè§†é¢‘</td>
      <td>Video-Play</td>
    </tr>
    <tr>
      <th>5</th>
      <td>æˆ‘æƒ³çœ‹å’Œå¹³ç²¾è‹±ä¸Šæˆ˜ç¥å¿…å¤‡æŠ€å·§çš„æ¸¸æˆè§†é¢‘</td>
      <td>Video-Play</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2019å¹´å¤è£…çˆ±æƒ…ç”µè§†å‰§å°å¥³èŠ±ä¸å¼ƒçš„èŠ±çµ®æ’­æ”¾ä¸€ä¸‹</td>
      <td>Video-Play</td>
    </tr>
    <tr>
      <th>7</th>
      <td>æ‰¾ä¸€ä¸ª2004å¹´çš„æ¨ç†å‰§ç»™æˆ‘çœ‹ä¸€ä¼šå‘¢</td>
      <td>FilmTele-Play</td>
    </tr>
    <tr>
      <th>8</th>
      <td>è‡ªé©¾æ¸¸å»æ·±åœ³éƒ½ç»è¿‡é‚£äº›åœ°æ–¹å•Š</td>
      <td>Travel-Query</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ç»™æˆ‘è½¬æ’­ä»Šå¤©çš„å¥³å­åŒæ‰“ä¹’ä¹“çƒæ¯”èµ›ç°åœº</td>
      <td>Video-Play</td>
    </tr>
  </tbody>
</table>
</div>



## 1.ç”Ÿæˆlabelæ–‡ä»¶


```python
labels=df[1].unique()
# æ‰“å¼€æ–‡ä»¶å¹¶å†™å…¥åˆ—è¡¨ä¸­çš„å…ƒç´   
with open('label.txt', 'w') as f:  
    for item in labels:  
        f.write(str(item) + '\n')
```


```python
!cat label.txt
```

    Travel-Query
    Music-Play
    FilmTele-Play
    Video-Play
    Radio-Listen
    HomeAppliance-Control
    Weather-Query
    Alarm-Update
    Calendar-Query
    TVProgram-Play
    Audio-Play
    Other



```python
%cd ~/PaddleNLP/applications/text_classification/multi_class
!mkdir data
```

    /home/aistudio/PaddleNLP/applications/text_classification/multi_class


## 2.åˆ’åˆ†æ•°æ®é›†
- train_test_splitç›´æ¥æŒ‰ç…§ 8:2 åˆ’åˆ†è®­ç»ƒé›†ã€æµ‹è¯•é›†


```python
import os
from sklearn.model_selection import train_test_split
# åˆ’åˆ†è®­ç»ƒåŠæµ‹è¯•é›†
train_data, dev_data= train_test_split( df, test_size=0.2)
root='data'
train_filename = os.path.join(root, 'train.txt')
dev_filename = os.path.join(root, 'dev.txt')
train_data.to_csv(train_filename, index=False, sep="\t", header=None)
dev_data.to_csv(dev_filename, index=False, sep="\t", header=None)
```

## 3.æ•°æ®æ•´ç†

è®­ç»ƒéœ€è¦å‡†å¤‡æŒ‡å®šæ ¼å¼çš„æœ¬åœ°æ•°æ®é›†,å¦‚æœæ²¡æœ‰å·²æ ‡æ³¨çš„æ•°æ®é›†ï¼Œå¯ä»¥å‚è€ƒ[æ–‡æœ¬åˆ†ç±»ä»»åŠ¡doccanoæ•°æ®æ ‡æ³¨ä½¿ç”¨æŒ‡å—](https://gitee.com/paddlepaddle/PaddleNLP/blob/develop/applications/text_classification/doccano.md)è¿›è¡Œæ–‡æœ¬åˆ†ç±»æ•°æ®æ ‡æ³¨ã€‚æŒ‡å®šæ ¼å¼æœ¬åœ°æ•°æ®é›†ç›®å½•ç»“æ„ï¼š

### 3.1ç›®å½•ç»“æ„

```bash
data/
â”œâ”€â”€ train.txt # è®­ç»ƒæ•°æ®é›†æ–‡ä»¶
â”œâ”€â”€ dev.txt # å¼€å‘æ•°æ®é›†æ–‡ä»¶
â””â”€â”€ label.txt # åˆ†ç±»æ ‡ç­¾æ–‡ä»¶
```

### 3.2æ•°æ®é›†æ ¼å¼
è®­ç»ƒã€å¼€å‘ã€æµ‹è¯•æ•°æ®é›† æ–‡ä»¶ä¸­æ–‡æœ¬ä¸æ ‡ç­¾ç±»åˆ«åç”¨tabç¬¦'\t'åˆ†éš”å¼€ï¼Œæ–‡æœ¬ä¸­é¿å…å‡ºç°tabç¬¦'\t'ã€‚

train.txt/dev.txt/test.txt æ–‡ä»¶æ ¼å¼ï¼š

```bash
<æ–‡æœ¬>'\t'<æ ‡ç­¾>
<æ–‡æœ¬>'\t'<æ ‡ç­¾>
...
```
### 3.3åˆ†ç±»æ ‡ç­¾æ ¼å¼
label.txt(åˆ†ç±»æ ‡ç­¾æ–‡ä»¶)è®°å½•æ•°æ®é›†ä¸­æ‰€æœ‰æ ‡ç­¾é›†åˆï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªæ ‡ç­¾åã€‚

- label.txt æ–‡ä»¶æ ¼å¼ï¼š

```bash
<æ ‡ç­¾>
<æ ‡ç­¾>

```


```python
!cp ~/data/data208091/test.csv data/test.txt
!cp ~/label.txt data/label.txt
```


```python
!tree data
```

    data
    â”œâ”€â”€ bad_case.txt
    â”œâ”€â”€ dev.txt
    â”œâ”€â”€ label.txt
    â”œâ”€â”€ test.txt
    â””â”€â”€ train.txt
    
    0 directories, 5 files


# å››ã€æ¨¡å‹è®­ç»ƒ

**ä½¿ç”¨ä½¿ç”¨ Trainer API å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ**

åªéœ€è¾“å…¥æ¨¡å‹ã€æ•°æ®é›†ç­‰å°±å¯ä»¥ä½¿ç”¨ Trainer API é«˜æ•ˆå¿«é€Ÿåœ°è¿›è¡Œé¢„è®­ç»ƒã€å¾®è°ƒå’Œæ¨¡å‹å‹ç¼©ç­‰ä»»åŠ¡ï¼Œå¯ä»¥ä¸€é”®å¯åŠ¨å¤šå¡è®­ç»ƒã€æ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦ç´¯ç§¯ã€æ–­ç‚¹é‡å¯ã€æ—¥å¿—æ˜¾ç¤ºç­‰åŠŸèƒ½ï¼ŒTrainer API è¿˜é’ˆå¯¹è®­ç»ƒè¿‡ç¨‹çš„é€šç”¨è®­ç»ƒé…ç½®åšäº†å°è£…ï¼Œæ¯”å¦‚ï¼šä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦ç­‰ã€‚



## 1.è®­ç»ƒå‚æ•°

ä¸»è¦çš„é…ç½®çš„å‚æ•°ä¸ºï¼š

- `do_train`: æ˜¯å¦è¿›è¡Œè®­ç»ƒã€‚
- `do_eval`: æ˜¯å¦è¿›è¡Œè¯„ä¼°ã€‚
- `debug`: ä¸`do_eval`é…åˆä½¿ç”¨ï¼Œæ˜¯å¦å¼€å¯debugæ¨¡å‹ï¼Œå¯¹æ¯ä¸€ä¸ªç±»åˆ«è¿›è¡Œè¯„ä¼°ã€‚
- `do_export`: è®­ç»ƒç»“æŸåæ˜¯å¦å¯¼å‡ºé™æ€å›¾ã€‚
- `do_compress`: è®­ç»ƒç»“æŸåæ˜¯å¦è¿›è¡Œæ¨¡å‹è£å‰ªã€‚
- `model_name_or_path`: å†…ç½®æ¨¡å‹åï¼Œæˆ–è€…æ¨¡å‹å‚æ•°é…ç½®ç›®å½•è·¯å¾„ã€‚é»˜è®¤ä¸º`ernie-3.0-tiny-medium-v2-zh`ã€‚
- `output_dir`: æ¨¡å‹å‚æ•°ã€è®­ç»ƒæ—¥å¿—å’Œé™æ€å›¾å¯¼å‡ºçš„ä¿å­˜ç›®å½•ã€‚
- `device`: ä½¿ç”¨çš„è®¾å¤‡ï¼Œé»˜è®¤ä¸º`gpu`ã€‚
- `num_train_epochs`: è®­ç»ƒè½®æ¬¡ï¼Œä½¿ç”¨æ—©åœæ³•æ—¶å¯ä»¥é€‰æ‹©100ã€‚
- `early_stopping`: æ˜¯å¦ä½¿ç”¨æ—©åœæ³•ï¼Œä¹Ÿå³ä¸€å®šè½®æ¬¡åè¯„ä¼°æŒ‡æ ‡ä¸å†å¢é•¿åˆ™åœæ­¢è®­ç»ƒã€‚
- `early_stopping_patience`: åœ¨è®¾å®šçš„æ—©åœè®­ç»ƒè½®æ¬¡å†…ï¼Œæ¨¡å‹åœ¨å¼€å‘é›†ä¸Šè¡¨ç°ä¸å†ä¸Šå‡ï¼Œè®­ç»ƒç»ˆæ­¢ï¼›é»˜è®¤ä¸º4ã€‚
- `learning_rate`: é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å‚æ•°åŸºç¡€å­¦ä¹ ç‡å¤§å°ï¼Œå°†ä¸learning rate scheduleräº§ç”Ÿçš„å€¼ç›¸ä¹˜ä½œä¸ºå½“å‰å­¦ä¹ ç‡ã€‚
- `max_length`: æœ€å¤§å¥å­é•¿åº¦ï¼Œè¶…è¿‡è¯¥é•¿åº¦çš„æ–‡æœ¬å°†è¢«æˆªæ–­ï¼Œä¸è¶³çš„ä»¥Padè¡¥å…¨ã€‚æç¤ºæ–‡æœ¬ä¸ä¼šè¢«æˆªæ–­ã€‚
- `per_device_train_batch_size`: æ¯æ¬¡è®­ç»ƒæ¯å¼ å¡ä¸Šçš„æ ·æœ¬æ•°é‡ã€‚å¯æ ¹æ®å®é™…GPUæ˜¾å­˜é€‚å½“è°ƒå°/è°ƒå¤§æ­¤é…ç½®ã€‚
- `per_device_eval_batch_size`: æ¯æ¬¡è¯„ä¼°æ¯å¼ å¡ä¸Šçš„æ ·æœ¬æ•°é‡ã€‚å¯æ ¹æ®å®é™…GPUæ˜¾å­˜é€‚å½“è°ƒå°/è°ƒå¤§æ­¤é…ç½®ã€‚
- `max_length`: æœ€å¤§å¥å­é•¿åº¦ï¼Œè¶…è¿‡è¯¥é•¿åº¦çš„æ–‡æœ¬å°†è¢«æˆªæ–­ï¼Œä¸è¶³çš„ä»¥Padè¡¥å…¨ã€‚æç¤ºæ–‡æœ¬ä¸ä¼šè¢«æˆªæ–­ã€‚
- `train_path`: è®­ç»ƒé›†è·¯å¾„ï¼Œé»˜è®¤ä¸º"./data/train.txt"ã€‚
- `dev_path`: å¼€å‘é›†é›†è·¯å¾„ï¼Œé»˜è®¤ä¸º"./data/dev.txt"ã€‚
- `test_path`: æµ‹è¯•é›†è·¯å¾„ï¼Œé»˜è®¤ä¸º"./data/dev.txt"ã€‚
- `label_path`: æ ‡ç­¾è·¯å¾„ï¼Œé»˜è®¤ä¸º"./data/label.txt"ã€‚
- `bad_case_path`: é”™è¯¯æ ·æœ¬ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º"./data/bad\_case.txt"ã€‚
- `width_mult_list`ï¼šè£å‰ªå®½åº¦ï¼ˆmulti headï¼‰ä¿ç•™çš„æ¯”ä¾‹åˆ—è¡¨ï¼Œè¡¨ç¤ºå¯¹self\_attentionä¸­çš„ `q`ã€`k`ã€`v` ä»¥åŠ `ffn` æƒé‡å®½åº¦çš„ä¿ç•™æ¯”ä¾‹ï¼Œä¿ç•™æ¯”ä¾‹ä¹˜ä»¥å®½åº¦ï¼ˆmulti haedæ•°é‡ï¼‰åº”ä¸ºæ•´æ•°ï¼›é»˜è®¤æ˜¯Noneã€‚ è®­ç»ƒè„šæœ¬æ”¯æŒæ‰€æœ‰`TraingArguments`çš„å‚æ•°ï¼Œæ›´å¤šå‚æ•°ä»‹ç»å¯å‚è€ƒ[TrainingArguments å‚æ•°ä»‹ç»](https://gitee.com/link?target=https%3A%2F%2Fpaddlenlp.readthedocs.io%2Fzh%2Flatest%2Ftrainer.html%23trainingarguments)ã€‚

## 2.å¼€å§‹è®­ç»ƒ


```python
!python train.py \
    --do_train \
    --do_eval \
    --do_export \
    --model_name_or_path ernie-3.0-tiny-medium-v2-zh \
    --output_dir checkpoint \
    --device gpu \
    --num_train_epochs 100 \
    --early_stopping True \
    --early_stopping_patience 5 \
    --learning_rate 3e-5 \
    --max_length 128 \
    --per_device_eval_batch_size 32 \
    --per_device_train_batch_size 32 \
    --metric_for_best_model accuracy \
    --load_best_model_at_end \
    --logging_steps 5 \
    --evaluation_strategy epoch \
    --save_strategy epoch \
    --save_total_limit 1    
```

## 3.è®­ç»ƒæ—¥å¿—

```bash
[2023-04-11 17:30:31,229] [    INFO] -   Num examples = 2420
[2023-04-11 17:30:31,229] [    INFO] -   Total prediction steps = 76
[2023-04-11 17:30:31,229] [    INFO] -   Pre device batch size = 32
[2023-04-11 17:30:31,229] [    INFO] -   Total Batch size = 32

  0%|                                                    | 0/76 [00:00<?, ?it/s]
  9%|â–ˆâ–ˆâ–ˆâ–ˆ                                        | 7/76 [00:00<00:01, 58.78it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 13/76 [00:00<00:01, 53.60it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 19/76 [00:00<00:01, 53.72it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 25/76 [00:00<00:00, 54.40it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 31/76 [00:00<00:00, 53.83it/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 37/76 [00:00<00:00, 53.93it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 43/76 [00:00<00:00, 54.07it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 49/76 [00:00<00:00, 53.70it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 55/76 [00:01<00:00, 54.41it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 61/76 [00:01<00:00, 53.62it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 67/76 [00:01<00:00, 53.80it/s]
                                                                                
eval_loss: 0.38935500383377075, eval_accuracy: 0.9347107438016529, eval_micro_precision: 0.9347107438016529, eval_micro_recall: 0.9347107438016529, eval_micro_f1: 0.9347107438016529, eval_macro_precision: 0.8868087630817776, eval_macro_recall: 0.883506204765109, eval_macro_f1: 0.8840559834605317, eval_runtime: 1.4272, eval_samples_per_second: 1695.617, eval_steps_per_second: 53.251, epoch: 12.0
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 3636/30300 [02:54<15:32, 28.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:01<00:00, 58.29it/s]
                                                                                [2023-04-11 17:30:32,658] [    INFO] - Saving model checkpoint to checkpoint/checkpoint-3636
[2023-04-11 17:30:32,659] [    INFO] - Configuration saved in checkpoint/checkpoint-3636/config.json
[2023-04-11 17:30:33,291] [    INFO] - tokenizer config file saved in checkpoint/checkpoint-3636/tokenizer_config.json
[2023-04-11 17:30:33,291] [    INFO] - Special tokens file saved in checkpoint/checkpoint-3636/special_tokens_map.json
[2023-04-11 17:30:34,681] [    INFO] - Deleting older checkpoint [checkpoint/checkpoint-3333] due to args.save_total_limit
[2023-04-11 17:30:34,814] [    INFO] - 
Training completed. 

[2023-04-11 17:30:34,814] [    INFO] - Loading best model from checkpoint/checkpoint-2121 (score: 0.9400826446280992).
train_runtime: 177.1813, train_samples_per_second: 5463.331, train_steps_per_second: 171.011, train_loss: 0.3273027794348789, epoch: 12.0
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 3636/30300 [02:57<21:39, 20.52it/s]
[2023-04-11 17:30:35,236] [    INFO] - Saving model checkpoint to checkpoint
[2023-04-11 17:30:35,238] [    INFO] - Configuration saved in checkpoint/config.json
[2023-04-11 17:30:35,875] [    INFO] - tokenizer config file saved in checkpoint/tokenizer_config.json
[2023-04-11 17:30:35,875] [    INFO] - Special tokens file saved in checkpoint/special_tokens_map.json
[2023-04-11 17:30:35,876] [    INFO] - ***** train metrics *****
[2023-04-11 17:30:35,876] [    INFO] -   epoch                    =       12.0
[2023-04-11 17:30:35,876] [    INFO] -   train_loss               =     0.3273
[2023-04-11 17:30:35,876] [    INFO] -   train_runtime            = 0:02:57.18
[2023-04-11 17:30:35,876] [    INFO] -   train_samples_per_second =   5463.331
[2023-04-11 17:30:35,876] [    INFO] -   train_steps_per_second   =    171.011
[2023-04-11 17:30:36,113] [    INFO] - ***** Running Evaluation *****
[2023-04-11 17:30:36,113] [    INFO] -   Num examples = 2420
[2023-04-11 17:30:36,113] [    INFO] -   Total prediction steps = 76
[2023-04-11 17:30:36,113] [    INFO] -   Pre device batch size = 32
[2023-04-11 17:30:36,113] [    INFO] -   Total Batch size = 32
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:01<00:00, 55.75it/s]
[2023-04-11 17:30:37,541] [    INFO] - ***** eval metrics *****
[2023-04-11 17:30:37,541] [    INFO] -   epoch                   =       12.0
[2023-04-11 17:30:37,541] [    INFO] -   eval_accuracy           =     0.9401
[2023-04-11 17:30:37,541] [    INFO] -   eval_loss               =     0.2693
[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_f1           =     0.8951
[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_precision    =     0.8971
[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_recall       =     0.8938
[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_f1           =     0.9401
[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_precision    =     0.9401
[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_recall       =     0.9401
[2023-04-11 17:30:37,541] [    INFO] -   eval_runtime            = 0:00:01.42
[2023-04-11 17:30:37,541] [    INFO] -   eval_samples_per_second =   1695.007
[2023-04-11 17:30:37,541] [    INFO] -   eval_steps_per_second   =     53.232
[2023-04-11 17:30:37,543] [    INFO] - Exporting inference model to checkpoint/export/model
[2023-04-11 17:30:43,826] [    INFO] - Inference model exported.
[2023-04-11 17:30:43,827] [    INFO] - tokenizer config file saved in checkpoint/export/tokenizer_config.json
[2023-04-11 17:30:43,827] [    INFO] - Special tokens file saved in checkpoint/export/special_tokens_map.json
[2023-04-11 17:30:43,827] [    INFO] - id2label file saved in checkpoint/export/id2label.json
```

## 4.è®­ç»ƒç»“æœå’Œå¯é€‰æ¨¡å‹

ç¨‹åºè¿è¡Œæ—¶å°†ä¼šè‡ªåŠ¨è¿›è¡Œè®­ç»ƒï¼Œè¯„ä¼°ã€‚åŒæ—¶è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ä¿å­˜å¼€å‘é›†ä¸Šæœ€ä½³æ¨¡å‹åœ¨æŒ‡å®šçš„ `output_dir` ä¸­ï¼Œä¿å­˜æ¨¡å‹æ–‡ä»¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
checkpoint/
â”œâ”€â”€ export # é™æ€å›¾æ¨¡å‹
â”œâ”€â”€ config.json # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ model_state.pdparams # æ¨¡å‹å‚æ•°æ–‡ä»¶
â”œâ”€â”€ tokenizer_config.json # åˆ†è¯å™¨é…ç½®æ–‡ä»¶
â”œâ”€â”€ vocab.txt
â””â”€â”€ special_tokens_map.json
```

- ä¸­æ–‡è®­ç»ƒä»»åŠ¡ï¼ˆæ–‡æœ¬æ”¯æŒå«éƒ¨åˆ†è‹±æ–‡ï¼‰æ¨èä½¿ç”¨"ernie-1.0-large-zh-cw"ã€"ernie-3.0-tiny-base-v2-zh"ã€"ernie-3.0-tiny-medium-v2-zh"ã€"ernie-3.0-tiny-micro-v2-zh"ã€"ernie-3.0-tiny-mini-v2-zh"ã€"ernie-3.0-tiny-nano-v2-zh"ã€"ernie-3.0-tiny-pico-v2-zh"ã€‚
- è‹±æ–‡è®­ç»ƒä»»åŠ¡æ¨èä½¿ç”¨"ernie-3.0-tiny-mini-v2-en"ã€ "ernie-2.0-base-en"ã€"ernie-2.0-large-en"ã€‚
- è‹±æ–‡å’Œä¸­æ–‡ä»¥å¤–è¯­è¨€çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œæ¨èä½¿ç”¨åŸºäº96ç§è¯­è¨€ï¼ˆæ¶µç›–æ³•è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ç­‰å‡ ä¹æ‰€æœ‰å¸¸è§è¯­è¨€ï¼‰è¿›è¡Œé¢„è®­ç»ƒçš„å¤šè¯­è¨€é¢„è®­ç»ƒæ¨¡å‹"ernie-m-base"ã€"ernie-m-large"ï¼Œè¯¦æƒ…è¯·å‚è§[ERNIE-Mè®ºæ–‡](https://gitee.com/link?target=https%3A%2F%2Farxiv.org%2Fpdf%2F2012.15674.pdf)ã€‚

# äº”ã€æ¨¡å‹è¯„ä¼°
è®­ç»ƒåçš„æ¨¡å‹æˆ‘ä»¬å¯ä»¥å¼€å¯debugæ¨¡å¼ï¼Œå¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ‰“å°é”™è¯¯é¢„æµ‹æ ·æœ¬ä¿å­˜åœ¨bad_case.txtã€‚é»˜è®¤åœ¨GPUç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œåœ¨CPUç¯å¢ƒä¸‹ä¿®æ”¹å‚æ•°é…ç½®ä¸º--device "cpu":

## 1.å¼€å§‹è®­ç»ƒ


```python
!python train.py \
    --do_eval \
    --debug True \
    --device gpu \
    --model_name_or_path checkpoint \
    --output_dir checkpoint \
    --per_device_eval_batch_size 32 \
    --max_length 128 \
    --test_path './data/dev.txt'
```

## 2.è¾“å‡ºæ—¥å¿—
```bash
[2023-04-11 17:38:48,156] [    INFO] - ----------------------------
[2023-04-11 17:38:48,156] [    INFO] - Class name: Calendar-Query
[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 241(10.0%) | precision: 99.17 | recall: 99.17 | F1 score 99.17
[2023-04-11 17:38:48,156] [    INFO] - ----------------------------
[2023-04-11 17:38:48,156] [    INFO] - Class name: TVProgram-Play
[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 47(1.9%) | precision: 71.43 | recall: 63.83 | F1 score 67.42
[2023-04-11 17:38:48,156] [    INFO] - ----------------------------
[2023-04-11 17:38:48,156] [    INFO] - Class name: Audio-Play
[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 49(2.0%) | precision: 78.43 | recall: 81.63 | F1 score 80.00
[2023-04-11 17:38:48,156] [    INFO] - ----------------------------
[2023-04-11 17:38:48,156] [    INFO] - Class name: Other
[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 40(1.7%) | precision: 65.85 | recall: 67.50 | F1 score 66.67
[2023-04-11 17:38:48,156] [    INFO] - ----------------------------
[2023-04-11 17:38:48,158] [    INFO] - Bad case in dev dataset saved in ./data/bad_case.txt
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:01<00:00, 55.79it/s]
```

## 3.é”™è¯¯åˆ†æ
é¢„æµ‹é”™è¯¯çš„ä¼šè¿›è¡Œé¢˜å‹ï¼Œbad caseã€‚

æ–‡æœ¬åˆ†ç±»é¢„æµ‹è¿‡ç¨‹ä¸­å¸¸ä¼šé‡åˆ°è¯¸å¦‚"æ¨¡å‹ä¸ºä»€ä¹ˆä¼šé¢„æµ‹å‡ºé”™è¯¯çš„ç»“æœ"ï¼Œ"å¦‚ä½•æå‡æ¨¡å‹çš„è¡¨ç°"ç­‰é—®é¢˜ã€‚[Analysisæ¨¡å—](https://gitee.com/paddlepaddle/PaddleNLP/blob/develop/applications/text_classification/multi_class/analysis) æä¾›äº†**å¯è§£é‡Šæ€§åˆ†æã€æ•°æ®ä¼˜åŒ–**ç­‰åŠŸèƒ½ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°åˆ†ææ–‡æœ¬åˆ†ç±»æ¨¡å‹é¢„æµ‹ç»“æœå’Œå¯¹æ¨¡å‹æ•ˆæœè¿›è¡Œä¼˜åŒ–ã€‚

å…·ä½“è§ bad_case.txt


```python
!head -n10 data/bad_case.txt
```

    Text	Label	Prediction
    ä¸€ç¦…å°å’Œå°šç¬¬4é›†å¾€åæ¥ç€æ’­æ”¾æˆ‘è¦çœ‹å‘¢	Video-Play	FilmTele-Play
    æµå—ç”Ÿæ´»çš„äº¤é€šè¿›è¡Œæ—¶è¿˜åœ¨ç›´æ’­ä¸­å—æˆ‘æƒ³çœ‹ä¸‹	TVProgram-Play	Video-Play
    èƒ½å¦å›æ”¾ä¸€ä¸‹æ—©ä¸Šä¸ƒç‚¹äºŒååˆ†çš„æ—¶äº‹å…³ææ¡ˆå—æˆ‘æƒ³çœ‹ä¸‹	Video-Play	TVProgram-Play
    æ’­æ”¾ä¸€ä¸‹é‚£ä¸ªå¯èˆª	FilmTele-Play	Music-Play
    ç”µè§†åªæœ‰å£°éŸ³è€Œæ²¡æœ‰å›¾åƒè¯¥æ‰“ä»€ä¹ˆå·ç çš„ç”µè¯	HomeAppliance-Control	Other
    æœ€è¿‘æœ‰ä»€ä¹ˆæ–°ç”µå½±ï¼Œè°ƒåˆ°å°æ¥šå’Œé‡è¥çš„èŠ‚ç›®çˆ±ç”µå½±äº†è§£ä¸€ä¸‹	Radio-Listen	TVProgram-Play
    é‚£å°„æ‰‹åº§å‘¢ç‰§ç¾Šåº§å‘¢ç‰§ç¾Šåº§æ˜¯ç™½ç¾Šåº§å—	Other	Calendar-Query
    é£è½®æµ·è´Ÿä¼¤æ’èˆè°¢æ­Œè¿·ä¸ºä¿æŒæœ€ä½³çŠ¶æ€è¿›è¡¥å›¾	Other	Video-Play
    å´å½¦ç¥–è¿˜è¡¨ç¤ºä¸€æ—¦è€å©†æœ‰äº†ä»–å°±ä¼šåœå·¥ä¸€å¹´å½“ä¸“ä¸šå¥¶çˆ¸	Music-Play	FilmTele-Play


# å…­ã€æºç åˆ†æ
## 1.train.py

```python


import functools
import json
import os
import shutil
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

import numpy as np
import paddle
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    precision_recall_fscore_support,
)
from utils import log_metrics_debug, preprocess_function, read_local_dataset

from paddlenlp.data import DataCollatorWithPadding
from paddlenlp.datasets import load_dataset
from paddlenlp.trainer import (
    CompressionArguments,
    EarlyStoppingCallback,
    PdArgumentParser,
    Trainer,
)
from paddlenlp.transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    export_model,
)
from paddlenlp.utils.log import logger


# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = [
    "ernie-1.0-large-zh-cw",
    "ernie-1.0-base-zh-cw",
    "ernie-3.0-xbase-zh",
    "ernie-3.0-base-zh",
    "ernie-3.0-medium-zh",
    "ernie-3.0-micro-zh",
    "ernie-3.0-mini-zh",
    "ernie-3.0-nano-zh",
    "ernie-3.0-tiny-base-v2-zh",
    "ernie-3.0-tiny-medium-v2-zh",
    "ernie-3.0-tiny-micro-v2-zh",
    "ernie-3.0-tiny-mini-v2-zh",
    "ernie-3.0-tiny-nano-v2-zh ",
    "ernie-3.0-tiny-pico-v2-zh",
    "ernie-2.0-large-en",
    "ernie-2.0-base-en",
    "ernie-3.0-tiny-mini-v2-en",
    "ernie-m-base",
    "ernie-m-large",
]


# é»˜è®¤å‚æ•°
# yapf: disable
@dataclass
class DataArguments:
    max_length: int = field(default=128, metadata={"help": "Maximum number of tokens for the model."})
    early_stopping: bool = field(default=False, metadata={"help": "Whether apply early stopping strategy."})
    early_stopping_patience: int = field(default=4, metadata={"help": "Stop training when the specified metric worsens for early_stopping_patience evaluation calls"})
    debug: bool = field(default=False, metadata={"help": "Whether choose debug mode."})
    train_path: str = field(default='./data/train.txt', metadata={"help": "Train dataset file path."})
    dev_path: str = field(default='./data/dev.txt', metadata={"help": "Dev dataset file path."})
    test_path: str = field(default='./data/dev.txt', metadata={"help": "Test dataset file path."})
    label_path: str = field(default='./data/label.txt', metadata={"help": "Label file path."})
    bad_case_path: str = field(default='./data/bad_case.txt', metadata={"help": "Bad case file path."})


@dataclass
class ModelArguments:
    model_name_or_path: str = field(default="ernie-3.0-tiny-medium-v2-zh", metadata={"help": "Build-in pretrained model name or the path to local model."})
    export_model_dir: Optional[str] = field(default=None, metadata={"help": "Path to directory to store the exported inference model."})
# yapf: enable


def main():
    """
    Training a binary or multi classification model
    """

    parser = PdArgumentParser((ModelArguments, DataArguments, CompressionArguments))
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
    if training_args.do_compress:
        training_args.strategy = "dynabert"
    if training_args.do_train or training_args.do_compress:
        training_args.print_config(model_args, "Model")
        training_args.print_config(data_args, "Data")
    paddle.set_device(training_args.device)

    # Define id2label
    id2label = {}
    label2id = {}
    with open(data_args.label_path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f):
            l = line.strip()
            id2label[i] = l
            label2id[l] = i

    # Define model & tokenizer
    if os.path.isdir(model_args.model_name_or_path):
        model = AutoModelForSequenceClassification.from_pretrained(
            model_args.model_name_or_path, label2id=label2id, id2label=id2label
        )
    elif model_args.model_name_or_path in SUPPORTED_MODELS:
        model = AutoModelForSequenceClassification.from_pretrained(
            model_args.model_name_or_path, num_classes=len(label2id), label2id=label2id, id2label=id2label
        )
    else:
        raise ValueError(
            f"{model_args.model_name_or_path} is not a supported model type. Either use a local model path or select a model from {SUPPORTED_MODELS}"
        )
    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)

    # load and preprocess dataset
    train_ds = load_dataset(read_local_dataset, path=data_args.train_path, label2id=label2id, lazy=False)
    dev_ds = load_dataset(read_local_dataset, path=data_args.dev_path, label2id=label2id, lazy=False)
    trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_length=data_args.max_length)
    train_ds = train_ds.map(trans_func)
    dev_ds = dev_ds.map(trans_func)

    if data_args.debug:
        test_ds = load_dataset(read_local_dataset, path=data_args.test_path, label2id=label2id, lazy=False)
        test_ds = test_ds.map(trans_func)

    # Define the metric function.
    def compute_metrics(eval_preds):
        pred_ids = np.argmax(eval_preds.predictions, axis=-1)
        metrics = {}
        metrics["accuracy"] = accuracy_score(y_true=eval_preds.label_ids, y_pred=pred_ids)
        for average in ["micro", "macro"]:
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_true=eval_preds.label_ids, y_pred=pred_ids, average=average
            )
            metrics[f"{average}_precision"] = precision
            metrics[f"{average}_recall"] = recall
            metrics[f"{average}_f1"] = f1
        return metrics

    def compute_metrics_debug(eval_preds):
        pred_ids = np.argmax(eval_preds.predictions, axis=-1)
        metrics = classification_report(eval_preds.label_ids, pred_ids, output_dict=True)
        return metrics

    # Define the early-stopping callback.
    if data_args.early_stopping:
        callbacks = [EarlyStoppingCallback(early_stopping_patience=data_args.early_stopping_patience)]
    else:
        callbacks = None

    # å®šä¹‰ Trainer
    trainer = Trainer(
        model=model,
        tokenizer=tokenizer,
        args=training_args,
        criterion=paddle.nn.loss.CrossEntropyLoss(),
        train_dataset=train_ds,
        eval_dataset=dev_ds,
        callbacks=callbacks,
        data_collator=DataCollatorWithPadding(tokenizer),
        compute_metrics=compute_metrics_debug if data_args.debug else compute_metrics,
    )

    # è®­ç»ƒ
    if training_args.do_train:
        train_result = trainer.train()
        metrics = train_result.metrics
        trainer.save_model()
        trainer.log_metrics("train", metrics)
        for checkpoint_path in Path(training_args.output_dir).glob("checkpoint-*"):
            shutil.rmtree(checkpoint_path)

    # æµ‹è¯•ã€é¢„æµ‹
    if training_args.do_eval:
        if data_args.debug:
            output = trainer.predict(test_ds)
            log_metrics_debug(output, id2label, test_ds, data_args.bad_case_path)
        else:
            eval_metrics = trainer.evaluate()
            trainer.log_metrics("eval", eval_metrics)

    # æ¨¡å‹å¯¼å‡º
    if training_args.do_export:
        if model.init_config["init_class"] in ["ErnieMForSequenceClassification"]:
            input_spec = [paddle.static.InputSpec(shape=[None, None], dtype="int64", name="input_ids")]
        else:
            input_spec = [
                paddle.static.InputSpec(shape=[None, None], dtype="int64", name="input_ids"),
                paddle.static.InputSpec(shape=[None, None], dtype="int64", name="token_type_ids"),
            ]
        if model_args.export_model_dir is None:
            model_args.export_model_dir = os.path.join(training_args.output_dir, "export")
        export_model(model=trainer.model, input_spec=input_spec, path=model_args.export_model_dir)
        tokenizer.save_pretrained(model_args.export_model_dir)
        id2label_file = os.path.join(model_args.export_model_dir, "id2label.json")
        with open(id2label_file, "w", encoding="utf-8") as f:
            json.dump(id2label, f, ensure_ascii=False)
            logger.info(f"id2label file saved in {id2label_file}")

    # æ¨¡å‹å‹ç¼©
    if training_args.do_compress:
        trainer.compress()
        for width_mult in training_args.width_mult_list:
            pruned_infer_model_dir = os.path.join(training_args.output_dir, "width_mult_" + str(round(width_mult, 2)))
            tokenizer.save_pretrained(pruned_infer_model_dir)
            id2label_file = os.path.join(pruned_infer_model_dir, "id2label.json")
            with open(id2label_file, "w", encoding="utf-8") as f:
                json.dump(id2label, f, ensure_ascii=False)
                logger.info(f"id2label file saved in {id2label_file}")

    for path in Path(training_args.output_dir).glob("runs"):
        shutil.rmtree(path)


if __name__ == "__main__":
    main()

```

## 2.utils.py

```python


import numpy as np

from paddlenlp.utils.log import logger

# é¢„å¤„ç†
def preprocess_function(examples, tokenizer, max_length, is_test=False):
    """
    Builds model inputs from a sequence for sequence classification tasks
    by concatenating and adding special tokens.
    """
    result = tokenizer(examples["text"], max_length=max_length, truncation=True)
    if not is_test:
        result["labels"] = np.array([examples["label"]], dtype="int64")
    return result

# è¯»å–æ•°æ®é›†
def read_local_dataset(path, label2id=None, is_test=False):
    """
    Read dataset.
    """
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            if is_test:
                sentence = line.strip()
                yield {"text": sentence}
            else:
                items = line.strip().split("\t")
                yield {"text": items[0], "label": label2id[items[1]]}


# æ‰“å°æ—¥å¿—                
def log_metrics_debug(output, id2label, dev_ds, bad_case_path):
    """
    Log metrics in debug mode.
    """
    predictions, label_ids, metrics = output
    pred_ids = np.argmax(predictions, axis=-1)
    logger.info("-----Evaluate model-------")
    logger.info("Dev dataset size: {}".format(len(dev_ds)))
    logger.info("Accuracy in dev dataset: {:.2f}%".format(metrics["test_accuracy"] * 100))
    logger.info(
        "Macro average | precision: {:.2f} | recall: {:.2f} | F1 score {:.2f}".format(
            metrics["test_macro avg"]["precision"] * 100,
            metrics["test_macro avg"]["recall"] * 100,
            metrics["test_macro avg"]["f1-score"] * 100,
        )
    )
    for i in id2label:
        l = id2label[i]
        logger.info("Class name: {}".format(l))
        i = "test_" + str(i)
        if i in metrics:
            logger.info(
                "Evaluation examples in dev dataset: {}({:.1f}%) | precision: {:.2f} | recall: {:.2f} | F1 score {:.2f}".format(
                    metrics[i]["support"],
                    100 * metrics[i]["support"] / len(dev_ds),
                    metrics[i]["precision"] * 100,
                    metrics[i]["recall"] * 100,
                    metrics[i]["f1-score"] * 100,
                )
            )
        else:
            logger.info("Evaluation examples in dev dataset: 0 (0%)")
        logger.info("----------------------------")

    with open(bad_case_path, "w", encoding="utf-8") as f:
        f.write("Text\tLabel\tPrediction\n")
        for i, (p, l) in enumerate(zip(pred_ids, label_ids)):
            p, l = int(p), int(l)
            if p != l:
                f.write(dev_ds.data[i]["text"] + "\t" + id2label[l] + "\t" + id2label[p] + "\n")

    logger.info("Bad case in dev dataset saved in {}".format(bad_case_path))

```

# ä¸ƒã€æ¨¡å‹é¢„æµ‹
ä½¿ç”¨taskflowè¿›è¡Œæ¨¡å‹é¢„æµ‹

- åŠ è½½æ¨¡å‹
- åŠ è½½æ•°æ®
- è¿›è¡Œé¢„æµ‹

## 1.åŠ è½½æ¨¡å‹è¿›è¡Œå•ä¸ªé¢„æµ‹


```python
from paddlenlp import Taskflow

# æ¨¡å‹é¢„æµ‹
cls = Taskflow("text_classification", task_path='checkpoint/export', is_static_model=True)
cls(["å›æ”¾CCTV2çš„æ¶ˆè´¹ä¸»å¼ "])
```

    [2023-04-11 17:42:26,315] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'checkpoint/export'.
    W0411 17:42:26.472223   349 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
    W0411 17:42:26.475904   349 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
    [2023-04-11 17:42:29,395] [    INFO] - Load id2label from checkpoint/export/id2label.json.





    [{'predictions': [{'label': 'TVProgram-Play', 'score': 0.9521104350237317}],
      'text': 'å›æ”¾CCTV2çš„æ¶ˆè´¹ä¸»å¼ '}]



## 2.è¯»å–å¾…é¢„æµ‹æ•°æ®
è¯»å–å¾…é¢„æµ‹æ•°æ®åˆ°åˆ—è¡¨


```python
with open('data/test.txt', 'r') as file:  
    mytests = file.readlines()

print(mytests[:3])
```

    ['å›æ”¾CCTV2çš„æ¶ˆè´¹ä¸»å¼ \n', 'ç»™æˆ‘æ‰“å¼€ç©å…·æˆ¿çš„ç¯\n', 'å¾ªç¯æ’­æ”¾èµµæœ¬å±±çš„å°å“ç›¸äº²æ¥å¬\n']


## 3.æ•´ä½“é¢„æµ‹


```python
result = cls(mytests)
```


```python
print(result[:3])
```

    [{'predictions': [{'label': 'TVProgram-Play', 'score': 0.9521104350237317}], 'text': 'å›æ”¾CCTV2çš„æ¶ˆè´¹ä¸»å¼ \n'}, {'predictions': [{'label': 'HomeAppliance-Control', 'score': 0.9970951493859599}], 'text': 'ç»™æˆ‘æ‰“å¼€ç©å…·æˆ¿çš„ç¯\n'}, {'predictions': [{'label': 'Audio-Play', 'score': 0.9710607817649783}], 'text': 'å¾ªç¯æ’­æ”¾èµµæœ¬å±±çš„å°å“ç›¸äº²æ¥å¬\n'}]


## 4.æŒ‰æ ¼å¼ä¿å­˜


```python
f=open('/home/aistudio/result.txt', 'w')
f.write("ID,Target\n")
for i in range(len(result)):
    f.write(f"{i+1},{result[i]['predictions'][0]['label']}\n")
f.close()
```


```python
!head -n10 /home/aistudio/result.txt
```

    ID,Target
    1,TVProgram-Play
    2,HomeAppliance-Control
    3,Audio-Play
    4,Alarm-Update
    5,HomeAppliance-Control
    6,FilmTele-Play
    7,FilmTele-Play
    8,Music-Play
    9,Calendar-Query


# å…«ã€æäº¤ç»“æœ

![](https://ai-studio-static-online.cdn.bcebos.com/6ac1d48783414efbae3fdae211d00f0e7b8a62a6ad4e4ebb84a9677c70d4d93d)

