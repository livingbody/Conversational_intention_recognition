{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 一、基于PaddleNLP的对话意图识别\n",
    "\n",
    "## 1.比赛介绍\n",
    "意图识别是指分析用户的核心需求，输出与查询输入最相关的信息，例如在搜索中要找电影、查快递、市政办公等需求，这些需求在底层的检索策略会有很大的不同，错误的识别几乎可以确定找不到能满足用户需求的内容，导致产生非常差的用户体验；在对话过程中要准确理解对方所想表达的意思，这是具有很大挑战性的任务。\n",
    "\n",
    "意图识别的准确性能在很大程度上影响着搜索的准确性和对话系统的智能性，在本赛题中我们需要选手对中文对话进行意图识别。\n",
    "\n",
    "## 2.数据集介绍\n",
    "- 训练数据：大约1.2万条中文对话\n",
    "- 测试数据：3000条无标注对话\n",
    "\n",
    "## 3.提交样式\n",
    "评分使用准确率进行评分，准确率值越大越好。\n",
    "\n",
    "- 实操方案不允许使用外部数据集，允许使用公开的外部预训练模型。\n",
    "- 实操方案需要在指定平台进行评分，提交csv格式。\n",
    "\n",
    "提交样例：\n",
    "```\n",
    "ID,Target\n",
    "1,TVProgram-Play\n",
    "2,HomeAppliance-Control\n",
    "3,Audio-Play\n",
    "4,Alarm-Update\n",
    "5,HomeAppliance-Control\n",
    "6,FilmTele-Play\n",
    "7,FilmTele-Play\n",
    "8,Music-Play\n",
    "9,Calendar-Query\n",
    "10,Video-Play\n",
    "11,Alarm-Update\n",
    "12,Music-Play\n",
    "13,Travel-Query\n",
    "14,TVProgram-Play\n",
    "```\n",
    "\n",
    "## 4.基本思路\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/247187fe7fab49c2b602d464409e57b2ea2679a7c0584f34bdb4b53503d88797)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T09:20:09.261685Z",
     "iopub.status.busy": "2023-04-11T09:20:09.260896Z",
     "iopub.status.idle": "2023-04-11T09:20:44.809109Z",
     "shell.execute_reply": "2023-04-11T09:20:44.808065Z",
     "shell.execute_reply.started": "2023-04-11T09:20:09.261654Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\r\n",
      "正克隆到 'PaddleNLP'...\r\n",
      "remote: Enumerating objects: 47494, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (34730/34730), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17072/17072), done.\u001b[K\r\n",
      "remote: Total 47494 (delta 23983), reused 27016 (delta 16711), pack-reused 12764\u001b[K\r\n",
      "接收对象中: 100% (47494/47494), 87.84 MiB | 4.86 MiB/s, 完成.\r\n",
      "处理 delta 中: 100% (32328/32328), 完成.\r\n",
      "检查连接... 完成。\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~\n",
    "!git clone https://gitee.com/paddlepaddle/PaddleNLP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T09:22:07.298419Z",
     "iopub.status.busy": "2023-04-11T09:22:07.297126Z",
     "iopub.status.idle": "2023-04-11T09:22:07.975593Z",
     "shell.execute_reply": "2023-04-11T09:22:07.974788Z",
     "shell.execute_reply.started": "2023-04-11T09:22:07.298357Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>还有双鸭山到淮阴的汽车票吗13号的</td>\n",
       "      <td>Travel-Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>从这里怎么回家</td>\n",
       "      <td>Travel-Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>随便播放一首专辑阁楼里的佛里的歌</td>\n",
       "      <td>Music-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>给看一下墓王之王嘛</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我想看挑战两把s686打突变团竞的游戏视频</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>我想看和平精英上战神必备技巧的游戏视频</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019年古装爱情电视剧小女花不弃的花絮播放一下</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>找一个2004年的推理剧给我看一会呢</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>自驾游去深圳都经过那些地方啊</td>\n",
       "      <td>Travel-Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>给我转播今天的女子双打乒乓球比赛现场</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0              1\n",
       "0         还有双鸭山到淮阴的汽车票吗13号的   Travel-Query\n",
       "1                   从这里怎么回家   Travel-Query\n",
       "2          随便播放一首专辑阁楼里的佛里的歌     Music-Play\n",
       "3                 给看一下墓王之王嘛  FilmTele-Play\n",
       "4     我想看挑战两把s686打突变团竞的游戏视频     Video-Play\n",
       "5       我想看和平精英上战神必备技巧的游戏视频     Video-Play\n",
       "6  2019年古装爱情电视剧小女花不弃的花絮播放一下     Video-Play\n",
       "7        找一个2004年的推理剧给我看一会呢  FilmTele-Play\n",
       "8            自驾游去深圳都经过那些地方啊   Travel-Query\n",
       "9        给我转播今天的女子双打乒乓球比赛现场     Video-Play"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('data/data208091/train.csv',sep='\\t',header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.生成label文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T09:22:11.273186Z",
     "iopub.status.busy": "2023-04-11T09:22:11.272194Z",
     "iopub.status.idle": "2023-04-11T09:22:11.409110Z",
     "shell.execute_reply": "2023-04-11T09:22:11.407711Z",
     "shell.execute_reply.started": "2023-04-11T09:22:11.273149Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels=df[1].unique()\n",
    "# 打开文件并写入列表中的元素  \n",
    "with open('label.txt', 'w') as f:  \n",
    "    for item in labels:  \n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:22:14.486774Z",
     "iopub.status.busy": "2023-04-11T09:22:14.486111Z",
     "iopub.status.idle": "2023-04-11T09:22:14.883675Z",
     "shell.execute_reply": "2023-04-11T09:22:14.882536Z",
     "shell.execute_reply.started": "2023-04-11T09:22:14.486735Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel-Query\r\n",
      "Music-Play\r\n",
      "FilmTele-Play\r\n",
      "Video-Play\r\n",
      "Radio-Listen\r\n",
      "HomeAppliance-Control\r\n",
      "Weather-Query\r\n",
      "Alarm-Update\r\n",
      "Calendar-Query\r\n",
      "TVProgram-Play\r\n",
      "Audio-Play\r\n",
      "Other\r\n"
     ]
    }
   ],
   "source": [
    "!cat label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T13:39:51.053891Z",
     "iopub.status.busy": "2023-04-11T13:39:51.052924Z",
     "iopub.status.idle": "2023-04-11T13:39:51.058741Z",
     "shell.execute_reply": "2023-04-11T13:39:51.057888Z",
     "shell.execute_reply.started": "2023-04-11T13:39:51.053857Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleNLP/applications/text_classification/multi_class\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~/PaddleNLP/applications/text_classification/multi_class\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.划分数据集\n",
    "- train_test_split直接按照 8:2 划分训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:22:49.092330Z",
     "iopub.status.busy": "2023-04-11T09:22:49.091502Z",
     "iopub.status.idle": "2023-04-11T09:22:49.602945Z",
     "shell.execute_reply": "2023-04-11T09:22:49.601988Z",
     "shell.execute_reply.started": "2023-04-11T09:22:49.092296Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练及测试集\n",
    "train_data, dev_data= train_test_split( df, test_size=0.2)\n",
    "root='data'\n",
    "train_filename = os.path.join(root, 'train.txt')\n",
    "dev_filename = os.path.join(root, 'dev.txt')\n",
    "train_data.to_csv(train_filename, index=False, sep=\"\\t\", header=None)\n",
    "dev_data.to_csv(dev_filename, index=False, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.数据整理\n",
    "\n",
    "训练需要准备指定格式的本地数据集,如果没有已标注的数据集，可以参考[文本分类任务doccano数据标注使用指南](https://gitee.com/paddlepaddle/PaddleNLP/blob/develop/applications/text_classification/doccano.md)进行文本分类数据标注。指定格式本地数据集目录结构：\n",
    "\n",
    "### 3.1目录结构\n",
    "\n",
    "```bash\n",
    "data/\n",
    "├── train.txt # 训练数据集文件\n",
    "├── dev.txt # 开发数据集文件\n",
    "└── label.txt # 分类标签文件\n",
    "```\n",
    "\n",
    "### 3.2数据集格式\n",
    "训练、开发、测试数据集 文件中文本与标签类别名用tab符'\\t'分隔开，文本中避免出现tab符'\\t'。\n",
    "\n",
    "train.txt/dev.txt/test.txt 文件格式：\n",
    "\n",
    "```bash\n",
    "<文本>'\\t'<标签>\n",
    "<文本>'\\t'<标签>\n",
    "...\n",
    "```\n",
    "### 3.3分类标签格式\n",
    "label.txt(分类标签文件)记录数据集中所有标签集合，每一行为一个标签名。\n",
    "\n",
    "- label.txt 文件格式：\n",
    "\n",
    "```bash\n",
    "<标签>\n",
    "<标签>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:22:54.487176Z",
     "iopub.status.busy": "2023-04-11T09:22:54.486182Z",
     "iopub.status.idle": "2023-04-11T09:22:55.373756Z",
     "shell.execute_reply": "2023-04-11T09:22:55.372678Z",
     "shell.execute_reply.started": "2023-04-11T09:22:54.487137Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp ~/data/data208091/test.csv data/test.txt\n",
    "!cp ~/label.txt data/label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T13:39:59.468343Z",
     "iopub.status.busy": "2023-04-11T13:39:59.467451Z",
     "iopub.status.idle": "2023-04-11T13:39:59.866049Z",
     "shell.execute_reply": "2023-04-11T13:39:59.864963Z",
     "shell.execute_reply.started": "2023-04-11T13:39:59.468314Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "├── bad_case.txt\r\n",
      "├── dev.txt\r\n",
      "├── label.txt\r\n",
      "├── test.txt\r\n",
      "└── train.txt\r\n",
      "\r\n",
      "0 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、模型训练\n",
    "\n",
    "**使用使用 Trainer API 对模型进行微调**\n",
    "\n",
    "只需输入模型、数据集等就可以使用 Trainer API 高效快速地进行预训练、微调和模型压缩等任务，可以一键启动多卡训练、混合精度训练、梯度累积、断点重启、日志显示等功能，Trainer API 还针对训练过程的通用训练配置做了封装，比如：优化器、学习率调度等。\n",
    "\n",
    "\n",
    "\n",
    "## 1.训练参数\n",
    "\n",
    "主要的配置的参数为：\n",
    "\n",
    "- `do_train`: 是否进行训练。\n",
    "- `do_eval`: 是否进行评估。\n",
    "- `debug`: 与`do_eval`配合使用，是否开启debug模型，对每一个类别进行评估。\n",
    "- `do_export`: 训练结束后是否导出静态图。\n",
    "- `do_compress`: 训练结束后是否进行模型裁剪。\n",
    "- `model_name_or_path`: 内置模型名，或者模型参数配置目录路径。默认为`ernie-3.0-tiny-medium-v2-zh`。\n",
    "- `output_dir`: 模型参数、训练日志和静态图导出的保存目录。\n",
    "- `device`: 使用的设备，默认为`gpu`。\n",
    "- `num_train_epochs`: 训练轮次，使用早停法时可以选择100。\n",
    "- `early_stopping`: 是否使用早停法，也即一定轮次后评估指标不再增长则停止训练。\n",
    "- `early_stopping_patience`: 在设定的早停训练轮次内，模型在开发集上表现不再上升，训练终止；默认为4。\n",
    "- `learning_rate`: 预训练语言模型参数基础学习率大小，将与learning rate scheduler产生的值相乘作为当前学习率。\n",
    "- `max_length`: 最大句子长度，超过该长度的文本将被截断，不足的以Pad补全。提示文本不会被截断。\n",
    "- `per_device_train_batch_size`: 每次训练每张卡上的样本数量。可根据实际GPU显存适当调小/调大此配置。\n",
    "- `per_device_eval_batch_size`: 每次评估每张卡上的样本数量。可根据实际GPU显存适当调小/调大此配置。\n",
    "- `max_length`: 最大句子长度，超过该长度的文本将被截断，不足的以Pad补全。提示文本不会被截断。\n",
    "- `train_path`: 训练集路径，默认为\"./data/train.txt\"。\n",
    "- `dev_path`: 开发集集路径，默认为\"./data/dev.txt\"。\n",
    "- `test_path`: 测试集路径，默认为\"./data/dev.txt\"。\n",
    "- `label_path`: 标签路径，默认为\"./data/label.txt\"。\n",
    "- `bad_case_path`: 错误样本保存路径，默认为\"./data/bad\\_case.txt\"。\n",
    "- `width_mult_list`：裁剪宽度（multi head）保留的比例列表，表示对self\\_attention中的 `q`、`k`、`v` 以及 `ffn` 权重宽度的保留比例，保留比例乘以宽度（multi haed数量）应为整数；默认是None。 训练脚本支持所有`TraingArguments`的参数，更多参数介绍可参考[TrainingArguments 参数介绍](https://gitee.com/link?target=https%3A%2F%2Fpaddlenlp.readthedocs.io%2Fzh%2Flatest%2Ftrainer.html%23trainingarguments)。\n",
    "\n",
    "## 2.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --model_name_or_path ernie-3.0-tiny-medium-v2-zh \\\n",
    "    --output_dir checkpoint \\\n",
    "    --device gpu \\\n",
    "    --num_train_epochs 100 \\\n",
    "    --early_stopping True \\\n",
    "    --early_stopping_patience 5 \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --max_length 128 \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --metric_for_best_model accuracy \\\n",
    "    --load_best_model_at_end \\\n",
    "    --logging_steps 5 \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --save_strategy epoch \\\n",
    "    --save_total_limit 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.训练日志\n",
    "\n",
    "```bash\n",
    "[2023-04-11 17:30:31,229] [    INFO] -   Num examples = 2420\n",
    "[2023-04-11 17:30:31,229] [    INFO] -   Total prediction steps = 76\n",
    "[2023-04-11 17:30:31,229] [    INFO] -   Pre device batch size = 32\n",
    "[2023-04-11 17:30:31,229] [    INFO] -   Total Batch size = 32\n",
    "\n",
    "  0%|                                                    | 0/76 [00:00<?, ?it/s]\n",
    "  9%|████                                        | 7/76 [00:00<00:01, 58.78it/s]\n",
    " 17%|███████▎                                   | 13/76 [00:00<00:01, 53.60it/s]\n",
    " 25%|██████████▊                                | 19/76 [00:00<00:01, 53.72it/s]\n",
    " 33%|██████████████▏                            | 25/76 [00:00<00:00, 54.40it/s]\n",
    " 41%|█████████████████▌                         | 31/76 [00:00<00:00, 53.83it/s]\n",
    " 49%|████████████████████▉                      | 37/76 [00:00<00:00, 53.93it/s]\n",
    " 57%|████████████████████████▎                  | 43/76 [00:00<00:00, 54.07it/s]\n",
    " 64%|███████████████████████████▋               | 49/76 [00:00<00:00, 53.70it/s]\n",
    " 72%|███████████████████████████████            | 55/76 [00:01<00:00, 54.41it/s]\n",
    " 80%|██████████████████████████████████▌        | 61/76 [00:01<00:00, 53.62it/s]\n",
    " 88%|█████████████████████████████████████▉     | 67/76 [00:01<00:00, 53.80it/s]\n",
    "                                                                                \n",
    "eval_loss: 0.38935500383377075, eval_accuracy: 0.9347107438016529, eval_micro_precision: 0.9347107438016529, eval_micro_recall: 0.9347107438016529, eval_micro_f1: 0.9347107438016529, eval_macro_precision: 0.8868087630817776, eval_macro_recall: 0.883506204765109, eval_macro_f1: 0.8840559834605317, eval_runtime: 1.4272, eval_samples_per_second: 1695.617, eval_steps_per_second: 53.251, epoch: 12.0\n",
    " 12%|████▌                                 | 3636/30300 [02:54<15:32, 28.61it/s]\n",
    "100%|███████████████████████████████████████████| 76/76 [00:01<00:00, 58.29it/s]\n",
    "                                                                                [2023-04-11 17:30:32,658] [    INFO] - Saving model checkpoint to checkpoint/checkpoint-3636\n",
    "[2023-04-11 17:30:32,659] [    INFO] - Configuration saved in checkpoint/checkpoint-3636/config.json\n",
    "[2023-04-11 17:30:33,291] [    INFO] - tokenizer config file saved in checkpoint/checkpoint-3636/tokenizer_config.json\n",
    "[2023-04-11 17:30:33,291] [    INFO] - Special tokens file saved in checkpoint/checkpoint-3636/special_tokens_map.json\n",
    "[2023-04-11 17:30:34,681] [    INFO] - Deleting older checkpoint [checkpoint/checkpoint-3333] due to args.save_total_limit\n",
    "[2023-04-11 17:30:34,814] [    INFO] - \n",
    "Training completed. \n",
    "\n",
    "[2023-04-11 17:30:34,814] [    INFO] - Loading best model from checkpoint/checkpoint-2121 (score: 0.9400826446280992).\n",
    "train_runtime: 177.1813, train_samples_per_second: 5463.331, train_steps_per_second: 171.011, train_loss: 0.3273027794348789, epoch: 12.0\n",
    " 12%|████▌                                 | 3636/30300 [02:57<21:39, 20.52it/s]\n",
    "[2023-04-11 17:30:35,236] [    INFO] - Saving model checkpoint to checkpoint\n",
    "[2023-04-11 17:30:35,238] [    INFO] - Configuration saved in checkpoint/config.json\n",
    "[2023-04-11 17:30:35,875] [    INFO] - tokenizer config file saved in checkpoint/tokenizer_config.json\n",
    "[2023-04-11 17:30:35,875] [    INFO] - Special tokens file saved in checkpoint/special_tokens_map.json\n",
    "[2023-04-11 17:30:35,876] [    INFO] - ***** train metrics *****\n",
    "[2023-04-11 17:30:35,876] [    INFO] -   epoch                    =       12.0\n",
    "[2023-04-11 17:30:35,876] [    INFO] -   train_loss               =     0.3273\n",
    "[2023-04-11 17:30:35,876] [    INFO] -   train_runtime            = 0:02:57.18\n",
    "[2023-04-11 17:30:35,876] [    INFO] -   train_samples_per_second =   5463.331\n",
    "[2023-04-11 17:30:35,876] [    INFO] -   train_steps_per_second   =    171.011\n",
    "[2023-04-11 17:30:36,113] [    INFO] - ***** Running Evaluation *****\n",
    "[2023-04-11 17:30:36,113] [    INFO] -   Num examples = 2420\n",
    "[2023-04-11 17:30:36,113] [    INFO] -   Total prediction steps = 76\n",
    "[2023-04-11 17:30:36,113] [    INFO] -   Pre device batch size = 32\n",
    "[2023-04-11 17:30:36,113] [    INFO] -   Total Batch size = 32\n",
    "100%|███████████████████████████████████████████| 76/76 [00:01<00:00, 55.75it/s]\n",
    "[2023-04-11 17:30:37,541] [    INFO] - ***** eval metrics *****\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   epoch                   =       12.0\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_accuracy           =     0.9401\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_loss               =     0.2693\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_f1           =     0.8951\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_precision    =     0.8971\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_macro_recall       =     0.8938\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_f1           =     0.9401\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_precision    =     0.9401\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_micro_recall       =     0.9401\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_runtime            = 0:00:01.42\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_samples_per_second =   1695.007\n",
    "[2023-04-11 17:30:37,541] [    INFO] -   eval_steps_per_second   =     53.232\n",
    "[2023-04-11 17:30:37,543] [    INFO] - Exporting inference model to checkpoint/export/model\n",
    "[2023-04-11 17:30:43,826] [    INFO] - Inference model exported.\n",
    "[2023-04-11 17:30:43,827] [    INFO] - tokenizer config file saved in checkpoint/export/tokenizer_config.json\n",
    "[2023-04-11 17:30:43,827] [    INFO] - Special tokens file saved in checkpoint/export/special_tokens_map.json\n",
    "[2023-04-11 17:30:43,827] [    INFO] - id2label file saved in checkpoint/export/id2label.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.训练结果和可选模型\n",
    "\n",
    "程序运行时将会自动进行训练，评估。同时训练过程中会自动保存开发集上最佳模型在指定的 `output_dir` 中，保存模型文件结构如下所示：\n",
    "\n",
    "```bash\n",
    "checkpoint/\n",
    "├── export # 静态图模型\n",
    "├── config.json # 模型配置文件\n",
    "├── model_state.pdparams # 模型参数文件\n",
    "├── tokenizer_config.json # 分词器配置文件\n",
    "├── vocab.txt\n",
    "└── special_tokens_map.json\n",
    "```\n",
    "\n",
    "- 中文训练任务（文本支持含部分英文）推荐使用\"ernie-1.0-large-zh-cw\"、\"ernie-3.0-tiny-base-v2-zh\"、\"ernie-3.0-tiny-medium-v2-zh\"、\"ernie-3.0-tiny-micro-v2-zh\"、\"ernie-3.0-tiny-mini-v2-zh\"、\"ernie-3.0-tiny-nano-v2-zh\"、\"ernie-3.0-tiny-pico-v2-zh\"。\n",
    "- 英文训练任务推荐使用\"ernie-3.0-tiny-mini-v2-en\"、 \"ernie-2.0-base-en\"、\"ernie-2.0-large-en\"。\n",
    "- 英文和中文以外语言的文本分类任务，推荐使用基于96种语言（涵盖法语、日语、韩语、德语、西班牙语等几乎所有常见语言）进行预训练的多语言预训练模型\"ernie-m-base\"、\"ernie-m-large\"，详情请参见[ERNIE-M论文](https://gitee.com/link?target=https%3A%2F%2Farxiv.org%2Fpdf%2F2012.15674.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、模型评估\n",
    "训练后的模型我们可以开启debug模式，对每个类别分别进行评估，并打印错误预测样本保存在bad_case.txt。默认在GPU环境下使用，在CPU环境下修改参数配置为--device \"cpu\":\n",
    "\n",
    "## 1.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --do_eval \\\n",
    "    --debug True \\\n",
    "    --device gpu \\\n",
    "    --model_name_or_path checkpoint \\\n",
    "    --output_dir checkpoint \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --max_length 128 \\\n",
    "    --test_path './data/dev.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.输出日志\n",
    "```bash\n",
    "[2023-04-11 17:38:48,156] [    INFO] - ----------------------------\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Class name: Calendar-Query\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 241(10.0%) | precision: 99.17 | recall: 99.17 | F1 score 99.17\n",
    "[2023-04-11 17:38:48,156] [    INFO] - ----------------------------\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Class name: TVProgram-Play\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 47(1.9%) | precision: 71.43 | recall: 63.83 | F1 score 67.42\n",
    "[2023-04-11 17:38:48,156] [    INFO] - ----------------------------\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Class name: Audio-Play\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 49(2.0%) | precision: 78.43 | recall: 81.63 | F1 score 80.00\n",
    "[2023-04-11 17:38:48,156] [    INFO] - ----------------------------\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Class name: Other\n",
    "[2023-04-11 17:38:48,156] [    INFO] - Evaluation examples in dev dataset: 40(1.7%) | precision: 65.85 | recall: 67.50 | F1 score 66.67\n",
    "[2023-04-11 17:38:48,156] [    INFO] - ----------------------------\n",
    "[2023-04-11 17:38:48,158] [    INFO] - Bad case in dev dataset saved in ./data/bad_case.txt\n",
    "100%|███████████████████████████████████████████| 76/76 [00:01<00:00, 55.79it/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.错误分析\n",
    "预测错误的会进行题型，bad case。\n",
    "\n",
    "文本分类预测过程中常会遇到诸如\"模型为什么会预测出错误的结果\"，\"如何提升模型的表现\"等问题。[Analysis模块](https://gitee.com/paddlepaddle/PaddleNLP/blob/develop/applications/text_classification/multi_class/analysis) 提供了**可解释性分析、数据优化**等功能，旨在帮助开发者更好地分析文本分类模型预测结果和对模型效果进行优化。\n",
    "\n",
    "具体见 bad_case.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T13:51:22.561372Z",
     "iopub.status.busy": "2023-04-11T13:51:22.560604Z",
     "iopub.status.idle": "2023-04-11T13:51:22.942528Z",
     "shell.execute_reply": "2023-04-11T13:51:22.941616Z",
     "shell.execute_reply.started": "2023-04-11T13:51:22.561336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tLabel\tPrediction\r\n",
      "一禅小和尚第4集往后接着播放我要看呢\tVideo-Play\tFilmTele-Play\r\n",
      "济南生活的交通进行时还在直播中吗我想看下\tTVProgram-Play\tVideo-Play\r\n",
      "能否回放一下早上七点二十分的时事关提案吗我想看下\tVideo-Play\tTVProgram-Play\r\n",
      "播放一下那个启航\tFilmTele-Play\tMusic-Play\r\n",
      "电视只有声音而没有图像该打什么号码的电话\tHomeAppliance-Control\tOther\r\n",
      "最近有什么新电影，调到小楚和野营的节目爱电影了解一下\tRadio-Listen\tTVProgram-Play\r\n",
      "那射手座呢牧羊座呢牧羊座是白羊座吗\tOther\tCalendar-Query\r\n",
      "飞轮海负伤排舞谢歌迷为保持最佳状态进补图\tOther\tVideo-Play\r\n",
      "吴彦祖还表示一旦老婆有了他就会停工一年当专业奶爸\tMusic-Play\tFilmTele-Play\r\n"
     ]
    }
   ],
   "source": [
    "!head -n10 data/bad_case.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、源码分析\n",
    "## 1.train.py\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "from utils import log_metrics_debug, preprocess_function, read_local_dataset\n",
    "\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.trainer import (\n",
    "    CompressionArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    PdArgumentParser,\n",
    "    Trainer,\n",
    ")\n",
    "from paddlenlp.transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    export_model,\n",
    ")\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "\n",
    "# 支持的模型列表\n",
    "SUPPORTED_MODELS = [\n",
    "    \"ernie-1.0-large-zh-cw\",\n",
    "    \"ernie-1.0-base-zh-cw\",\n",
    "    \"ernie-3.0-xbase-zh\",\n",
    "    \"ernie-3.0-base-zh\",\n",
    "    \"ernie-3.0-medium-zh\",\n",
    "    \"ernie-3.0-micro-zh\",\n",
    "    \"ernie-3.0-mini-zh\",\n",
    "    \"ernie-3.0-nano-zh\",\n",
    "    \"ernie-3.0-tiny-base-v2-zh\",\n",
    "    \"ernie-3.0-tiny-medium-v2-zh\",\n",
    "    \"ernie-3.0-tiny-micro-v2-zh\",\n",
    "    \"ernie-3.0-tiny-mini-v2-zh\",\n",
    "    \"ernie-3.0-tiny-nano-v2-zh \",\n",
    "    \"ernie-3.0-tiny-pico-v2-zh\",\n",
    "    \"ernie-2.0-large-en\",\n",
    "    \"ernie-2.0-base-en\",\n",
    "    \"ernie-3.0-tiny-mini-v2-en\",\n",
    "    \"ernie-m-base\",\n",
    "    \"ernie-m-large\",\n",
    "]\n",
    "\n",
    "\n",
    "# 默认参数\n",
    "# yapf: disable\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    max_length: int = field(default=128, metadata={\"help\": \"Maximum number of tokens for the model.\"})\n",
    "    early_stopping: bool = field(default=False, metadata={\"help\": \"Whether apply early stopping strategy.\"})\n",
    "    early_stopping_patience: int = field(default=4, metadata={\"help\": \"Stop training when the specified metric worsens for early_stopping_patience evaluation calls\"})\n",
    "    debug: bool = field(default=False, metadata={\"help\": \"Whether choose debug mode.\"})\n",
    "    train_path: str = field(default='./data/train.txt', metadata={\"help\": \"Train dataset file path.\"})\n",
    "    dev_path: str = field(default='./data/dev.txt', metadata={\"help\": \"Dev dataset file path.\"})\n",
    "    test_path: str = field(default='./data/dev.txt', metadata={\"help\": \"Test dataset file path.\"})\n",
    "    label_path: str = field(default='./data/label.txt', metadata={\"help\": \"Label file path.\"})\n",
    "    bad_case_path: str = field(default='./data/bad_case.txt', metadata={\"help\": \"Bad case file path.\"})\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: str = field(default=\"ernie-3.0-tiny-medium-v2-zh\", metadata={\"help\": \"Build-in pretrained model name or the path to local model.\"})\n",
    "    export_model_dir: Optional[str] = field(default=None, metadata={\"help\": \"Path to directory to store the exported inference model.\"})\n",
    "# yapf: enable\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Training a binary or multi classification model\n",
    "    \"\"\"\n",
    "\n",
    "    parser = PdArgumentParser((ModelArguments, DataArguments, CompressionArguments))\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    if training_args.do_compress:\n",
    "        training_args.strategy = \"dynabert\"\n",
    "    if training_args.do_train or training_args.do_compress:\n",
    "        training_args.print_config(model_args, \"Model\")\n",
    "        training_args.print_config(data_args, \"Data\")\n",
    "    paddle.set_device(training_args.device)\n",
    "\n",
    "    # Define id2label\n",
    "    id2label = {}\n",
    "    label2id = {}\n",
    "    with open(data_args.label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            l = line.strip()\n",
    "            id2label[i] = l\n",
    "            label2id[l] = i\n",
    "\n",
    "    # Define model & tokenizer\n",
    "    if os.path.isdir(model_args.model_name_or_path):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_args.model_name_or_path, label2id=label2id, id2label=id2label\n",
    "        )\n",
    "    elif model_args.model_name_or_path in SUPPORTED_MODELS:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_args.model_name_or_path, num_classes=len(label2id), label2id=label2id, id2label=id2label\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"{model_args.model_name_or_path} is not a supported model type. Either use a local model path or select a model from {SUPPORTED_MODELS}\"\n",
    "        )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)\n",
    "\n",
    "    # load and preprocess dataset\n",
    "    train_ds = load_dataset(read_local_dataset, path=data_args.train_path, label2id=label2id, lazy=False)\n",
    "    dev_ds = load_dataset(read_local_dataset, path=data_args.dev_path, label2id=label2id, lazy=False)\n",
    "    trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_length=data_args.max_length)\n",
    "    train_ds = train_ds.map(trans_func)\n",
    "    dev_ds = dev_ds.map(trans_func)\n",
    "\n",
    "    if data_args.debug:\n",
    "        test_ds = load_dataset(read_local_dataset, path=data_args.test_path, label2id=label2id, lazy=False)\n",
    "        test_ds = test_ds.map(trans_func)\n",
    "\n",
    "    # Define the metric function.\n",
    "    def compute_metrics(eval_preds):\n",
    "        pred_ids = np.argmax(eval_preds.predictions, axis=-1)\n",
    "        metrics = {}\n",
    "        metrics[\"accuracy\"] = accuracy_score(y_true=eval_preds.label_ids, y_pred=pred_ids)\n",
    "        for average in [\"micro\", \"macro\"]:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=eval_preds.label_ids, y_pred=pred_ids, average=average\n",
    "            )\n",
    "            metrics[f\"{average}_precision\"] = precision\n",
    "            metrics[f\"{average}_recall\"] = recall\n",
    "            metrics[f\"{average}_f1\"] = f1\n",
    "        return metrics\n",
    "\n",
    "    def compute_metrics_debug(eval_preds):\n",
    "        pred_ids = np.argmax(eval_preds.predictions, axis=-1)\n",
    "        metrics = classification_report(eval_preds.label_ids, pred_ids, output_dict=True)\n",
    "        return metrics\n",
    "\n",
    "    # Define the early-stopping callback.\n",
    "    if data_args.early_stopping:\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=data_args.early_stopping_patience)]\n",
    "    else:\n",
    "        callbacks = None\n",
    "\n",
    "    # 定义 Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        criterion=paddle.nn.loss.CrossEntropyLoss(),\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=dev_ds,\n",
    "        callbacks=callbacks,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        compute_metrics=compute_metrics_debug if data_args.debug else compute_metrics,\n",
    "    )\n",
    "\n",
    "    # 训练\n",
    "    if training_args.do_train:\n",
    "        train_result = trainer.train()\n",
    "        metrics = train_result.metrics\n",
    "        trainer.save_model()\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        for checkpoint_path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n",
    "            shutil.rmtree(checkpoint_path)\n",
    "\n",
    "    # 测试、预测\n",
    "    if training_args.do_eval:\n",
    "        if data_args.debug:\n",
    "            output = trainer.predict(test_ds)\n",
    "            log_metrics_debug(output, id2label, test_ds, data_args.bad_case_path)\n",
    "        else:\n",
    "            eval_metrics = trainer.evaluate()\n",
    "            trainer.log_metrics(\"eval\", eval_metrics)\n",
    "\n",
    "    # 模型导出\n",
    "    if training_args.do_export:\n",
    "        if model.init_config[\"init_class\"] in [\"ErnieMForSequenceClassification\"]:\n",
    "            input_spec = [paddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"input_ids\")]\n",
    "        else:\n",
    "            input_spec = [\n",
    "                paddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"input_ids\"),\n",
    "                paddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"token_type_ids\"),\n",
    "            ]\n",
    "        if model_args.export_model_dir is None:\n",
    "            model_args.export_model_dir = os.path.join(training_args.output_dir, \"export\")\n",
    "        export_model(model=trainer.model, input_spec=input_spec, path=model_args.export_model_dir)\n",
    "        tokenizer.save_pretrained(model_args.export_model_dir)\n",
    "        id2label_file = os.path.join(model_args.export_model_dir, \"id2label.json\")\n",
    "        with open(id2label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(id2label, f, ensure_ascii=False)\n",
    "            logger.info(f\"id2label file saved in {id2label_file}\")\n",
    "\n",
    "    # 模型压缩\n",
    "    if training_args.do_compress:\n",
    "        trainer.compress()\n",
    "        for width_mult in training_args.width_mult_list:\n",
    "            pruned_infer_model_dir = os.path.join(training_args.output_dir, \"width_mult_\" + str(round(width_mult, 2)))\n",
    "            tokenizer.save_pretrained(pruned_infer_model_dir)\n",
    "            id2label_file = os.path.join(pruned_infer_model_dir, \"id2label.json\")\n",
    "            with open(id2label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(id2label, f, ensure_ascii=False)\n",
    "                logger.info(f\"id2label file saved in {id2label_file}\")\n",
    "\n",
    "    for path in Path(training_args.output_dir).glob(\"runs\"):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "```\n",
    "\n",
    "## 2.utils.py\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "# 预处理\n",
    "def preprocess_function(examples, tokenizer, max_length, is_test=False):\n",
    "    \"\"\"\n",
    "    Builds model inputs from a sequence for sequence classification tasks\n",
    "    by concatenating and adding special tokens.\n",
    "    \"\"\"\n",
    "    result = tokenizer(examples[\"text\"], max_length=max_length, truncation=True)\n",
    "    if not is_test:\n",
    "        result[\"labels\"] = np.array([examples[\"label\"]], dtype=\"int64\")\n",
    "    return result\n",
    "\n",
    "# 读取数据集\n",
    "def read_local_dataset(path, label2id=None, is_test=False):\n",
    "    \"\"\"\n",
    "    Read dataset.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if is_test:\n",
    "                sentence = line.strip()\n",
    "                yield {\"text\": sentence}\n",
    "            else:\n",
    "                items = line.strip().split(\"\\t\")\n",
    "                yield {\"text\": items[0], \"label\": label2id[items[1]]}\n",
    "\n",
    "\n",
    "# 打印日志                \n",
    "def log_metrics_debug(output, id2label, dev_ds, bad_case_path):\n",
    "    \"\"\"\n",
    "    Log metrics in debug mode.\n",
    "    \"\"\"\n",
    "    predictions, label_ids, metrics = output\n",
    "    pred_ids = np.argmax(predictions, axis=-1)\n",
    "    logger.info(\"-----Evaluate model-------\")\n",
    "    logger.info(\"Dev dataset size: {}\".format(len(dev_ds)))\n",
    "    logger.info(\"Accuracy in dev dataset: {:.2f}%\".format(metrics[\"test_accuracy\"] * 100))\n",
    "    logger.info(\n",
    "        \"Macro average | precision: {:.2f} | recall: {:.2f} | F1 score {:.2f}\".format(\n",
    "            metrics[\"test_macro avg\"][\"precision\"] * 100,\n",
    "            metrics[\"test_macro avg\"][\"recall\"] * 100,\n",
    "            metrics[\"test_macro avg\"][\"f1-score\"] * 100,\n",
    "        )\n",
    "    )\n",
    "    for i in id2label:\n",
    "        l = id2label[i]\n",
    "        logger.info(\"Class name: {}\".format(l))\n",
    "        i = \"test_\" + str(i)\n",
    "        if i in metrics:\n",
    "            logger.info(\n",
    "                \"Evaluation examples in dev dataset: {}({:.1f}%) | precision: {:.2f} | recall: {:.2f} | F1 score {:.2f}\".format(\n",
    "                    metrics[i][\"support\"],\n",
    "                    100 * metrics[i][\"support\"] / len(dev_ds),\n",
    "                    metrics[i][\"precision\"] * 100,\n",
    "                    metrics[i][\"recall\"] * 100,\n",
    "                    metrics[i][\"f1-score\"] * 100,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"Evaluation examples in dev dataset: 0 (0%)\")\n",
    "        logger.info(\"----------------------------\")\n",
    "\n",
    "    with open(bad_case_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Text\\tLabel\\tPrediction\\n\")\n",
    "        for i, (p, l) in enumerate(zip(pred_ids, label_ids)):\n",
    "            p, l = int(p), int(l)\n",
    "            if p != l:\n",
    "                f.write(dev_ds.data[i][\"text\"] + \"\\t\" + id2label[l] + \"\\t\" + id2label[p] + \"\\n\")\n",
    "\n",
    "    logger.info(\"Bad case in dev dataset saved in {}\".format(bad_case_path))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、模型预测\n",
    "使用taskflow进行模型预测\n",
    "\n",
    "- 加载模型\n",
    "- 加载数据\n",
    "- 进行预测\n",
    "\n",
    "## 1.加载模型进行单个预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:42:23.427726Z",
     "iopub.status.busy": "2023-04-11T09:42:23.426921Z",
     "iopub.status.idle": "2023-04-11T09:42:29.867141Z",
     "shell.execute_reply": "2023-04-11T09:42:29.866111Z",
     "shell.execute_reply.started": "2023-04-11T09:42:23.427691Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-11 17:42:26,315] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'checkpoint/export'.\r\n",
      "W0411 17:42:26.472223   349 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0411 17:42:26.475904   349 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-04-11 17:42:29,395] [    INFO] - Load id2label from checkpoint/export/id2label.json.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'predictions': [{'label': 'TVProgram-Play', 'score': 0.9521104350237317}],\n",
       "  'text': '回放CCTV2的消费主张'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "\n",
    "# 模型预测\n",
    "cls = Taskflow(\"text_classification\", task_path='checkpoint/export', is_static_model=True)\n",
    "cls([\"回放CCTV2的消费主张\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.读取待预测数据\n",
    "读取待预测数据到列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:44:13.857534Z",
     "iopub.status.busy": "2023-04-11T09:44:13.856691Z",
     "iopub.status.idle": "2023-04-11T09:44:13.863700Z",
     "shell.execute_reply": "2023-04-11T09:44:13.863001Z",
     "shell.execute_reply.started": "2023-04-11T09:44:13.857494Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['回放CCTV2的消费主张\\n', '给我打开玩具房的灯\\n', '循环播放赵本山的小品相亲来听\\n']\r\n"
     ]
    }
   ],
   "source": [
    "with open('data/test.txt', 'r') as file:  \n",
    "    mytests = file.readlines()\n",
    "\n",
    "print(mytests[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.整体预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T09:48:02.455860Z",
     "iopub.status.busy": "2023-04-11T09:48:02.454956Z",
     "iopub.status.idle": "2023-04-11T09:48:07.325681Z",
     "shell.execute_reply": "2023-04-11T09:48:07.324312Z",
     "shell.execute_reply.started": "2023-04-11T09:48:02.455824Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = cls(mytests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T10:00:23.925901Z",
     "iopub.status.busy": "2023-04-11T10:00:23.925168Z",
     "iopub.status.idle": "2023-04-11T10:00:23.930531Z",
     "shell.execute_reply": "2023-04-11T10:00:23.929816Z",
     "shell.execute_reply.started": "2023-04-11T10:00:23.925872Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'predictions': [{'label': 'TVProgram-Play', 'score': 0.9521104350237317}], 'text': '回放CCTV2的消费主张\\n'}, {'predictions': [{'label': 'HomeAppliance-Control', 'score': 0.9970951493859599}], 'text': '给我打开玩具房的灯\\n'}, {'predictions': [{'label': 'Audio-Play', 'score': 0.9710607817649783}], 'text': '循环播放赵本山的小品相亲来听\\n'}]\r\n"
     ]
    }
   ],
   "source": [
    "print(result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.按格式保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T10:00:39.293520Z",
     "iopub.status.busy": "2023-04-11T10:00:39.292407Z",
     "iopub.status.idle": "2023-04-11T10:00:39.354210Z",
     "shell.execute_reply": "2023-04-11T10:00:39.353490Z",
     "shell.execute_reply.started": "2023-04-11T10:00:39.293474Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f=open('/home/aistudio/result.txt', 'w')\n",
    "f.write(\"ID,Target\\n\")\n",
    "for i in range(len(result)):\n",
    "    f.write(f\"{i+1},{result[i]['predictions'][0]['label']}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T13:53:55.610037Z",
     "iopub.status.busy": "2023-04-11T13:53:55.608917Z",
     "iopub.status.idle": "2023-04-11T13:53:55.988965Z",
     "shell.execute_reply": "2023-04-11T13:53:55.987878Z",
     "shell.execute_reply.started": "2023-04-11T13:53:55.609975Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,Target\r\n",
      "1,TVProgram-Play\r\n",
      "2,HomeAppliance-Control\r\n",
      "3,Audio-Play\r\n",
      "4,Alarm-Update\r\n",
      "5,HomeAppliance-Control\r\n",
      "6,FilmTele-Play\r\n",
      "7,FilmTele-Play\r\n",
      "8,Music-Play\r\n",
      "9,Calendar-Query\r\n"
     ]
    }
   ],
   "source": [
    "!head -n10 /home/aistudio/result.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、提交结果\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6ac1d48783414efbae3fdae211d00f0e7b8a62a6ad4e4ebb84a9677c70d4d93d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
